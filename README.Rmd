---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# TextEvalR (WIP)

<!-- badges: start -->
<!-- badges: end -->

Implementation of text-evaluation metric BLEU [Papineni et al, 2002](https://aclanthology.org/P02-1040.pdf) in *R*.

## Installation

``` r
library(devtools)
devtools::install_github("https://github.com/LazerLambda/TextEvalR")
```

## Example

Compute BLEU-score on a sample from the [WMT 22 Metrics Shared Task](https://wmt-metrics-task.github.io/).

``` r
library(TextEvalR)

ref <- list(
  c("The goods cost less than 20 euros.",
    "The merchandise was less than 20 EURO."),
  c("The fee would equal 40% of the value of the goods...",
    "The fee corresponds with 40 % of the goodsâ€™ value..."),
  c("I am #PRS_ORG# a serious customer and that is why it is not a problem for me.",
    "I am a major client of #PRS_ORG# and thus it is no problem for me."))
cand <- c("The goods cost less than 20 euros.",
    "The fee corresponds to 40% of the value of the goods....",
    "I'm a #PRS_ORG# major customer so it's not a problem for me.")
bleu(ref, cand)
```
